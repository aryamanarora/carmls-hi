{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5176be76d2724d3d9728a0cec5fb4921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee149f03b344e1c90deebb9cbbadbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os, csv\n",
    "from models import SNACSDataset\n",
    "\n",
    "# MODELS\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "    output_hidden_states = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['मैंने', 'Experiencer', 'Agent', 2, 0], ['तेरा', 'Theme', 'Theme', 2, 5], ['उसकी', 'Gestalt', 'Gestalt', 2, 14], ['तक', 'Duration', 'EndTime', 3, 9], ['मेरे', 'Possessor', 'Possessor', 3, 11], ['का', 'Purpose', 'Purpose', 3, 26], ['का', 'Gestalt', 'Gestalt', 3, 51], ['इसका', 'Topic', 'Topic', 4, 0], ['मुझे', 'Recipient', 'Recipient', 4, 7], ['तुझसे', 'Agent', 'Ancillary', 4, 11]]\n",
      "2450\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "\n",
    "data = []\n",
    "sentences = []\n",
    "current_sentence = []\n",
    "length = 0\n",
    "\n",
    "out_of_vocab = {'ड़': 'ड़', 'ढ़': 'ढ़', '‘': '', '‘': '', \"'\": '', '\"': ''}\n",
    "\n",
    "for entry in os.scandir('../annotations/lp_aryaman'):\n",
    "    if entry.path.endswith('.csv'):\n",
    "        \n",
    "        with open(entry, 'r') as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            for i, row in enumerate(reader):\n",
    "                if i == 0: continue\n",
    "                \n",
    "                for i, j in out_of_vocab.items():\n",
    "                    row[0] = row[0].replace(i, j)\n",
    "                \n",
    "                if row[0] == '':\n",
    "                    if current_sentence:\n",
    "                        sentences.append(current_sentence)\n",
    "                        length = 0\n",
    "                    current_sentence = []\n",
    "                else:\n",
    "                    if row[2]: data.append([row[0], row[2], row[3], len(sentences), length])\n",
    "                    length += len(row[0])\n",
    "                    current_sentence.append(row[0])\n",
    "\n",
    "        if current_sentence:\n",
    "            sentences.append(current_sentence)\n",
    "            \n",
    "# this is our training data\n",
    "print(data[:10])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ओह !\n",
      "1722\n",
      "[['[CLS]', 'ओ', '##ह', '!', '[SEP]'], ['[CLS]', 'न', '##न्', '##हे', '##ं', 'र', '##ाज', '##क', '##ु', '##मा', '##र', '!', '[SEP]'], ['[CLS]', 'म', '##ैं', '##ने', 'ते', '##रा', 'जीवन', ',', 'उसकी', 'उ', '##दा', '##सी', 'ध', '##ीर', '##े', '-', 'ध', '##ीर', '##े', 'स', '##म', '##झ', 'ली', 'थी', '[SEP]'], ['[CLS]', 'बहुत', 'दिन', '##ों', 'तक', 'मे', '##रे', 'पास', 'म', '##न', 'ब', '##ह', '##ला', '##ने', 'का', 'एक', 'मात्रा', 'स', '##ा', '##धन', 'था', 'स', '##ूर', '##्यास', '##्त', 'का', 'स', '##ौ', '##ंदर', '##्य', '।', '[SEP]'], ['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize sentences\n",
    "print(' '.join(sentences[0]))\n",
    "sentences = [tokenizer.tokenize('[CLS] ' + ' '.join(sentence) + ' [SEP]') for sentence in sentences]\n",
    "\n",
    "print(len(sentences))\n",
    "print(sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 863, 17110, 106, 102]\n",
      "['[CLS]', 'ओ', '##ह', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = [tokenizer.convert_tokens_to_ids(sentence) for sentence in sentences]\n",
    "print(indexed_tokens[0])\n",
    "print(sentences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n"
     ]
    }
   ],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers.\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i, sentence in enumerate(indexed_tokens):\n",
    "        if len(sentence) == 0:\n",
    "            outputs.append([])\n",
    "            continue\n",
    "        # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "        segments_ids = [1] * len(sentence)\n",
    "        if i % 10 == 0: print(i)\n",
    "        \n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([sentence])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        \n",
    "        outputs.append(model(tokens_tensor, segments_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3722, -0.2836,  0.2937,  ...,  0.6907,  0.2142,  0.2329],\n",
       "         [ 0.3534, -0.5321,  0.2235,  ...,  1.0148,  0.1673,  0.2986],\n",
       "         [ 0.6164, -0.2585,  0.7959,  ...,  0.7183, -0.1231, -0.1010],\n",
       "         [ 0.3348, -0.2729,  0.5100,  ...,  0.6602,  0.1632,  0.2698],\n",
       "         [ 0.4161, -0.2375,  0.4754,  ...,  0.4744,  0.0905,  0.2347]]]), pooler_output=tensor([[ 3.3972e-01,  2.4252e-01,  8.5810e-02,  6.2661e-02, -1.4015e-01,\n",
       "          1.4702e-01,  7.4292e-02, -2.9657e-02,  6.9910e-02,  1.9596e-01,\n",
       "         -1.1321e-03, -1.0474e-01, -3.1804e-01, -1.2298e-01,  1.4344e-01,\n",
       "          9.6834e-02,  3.1660e-02,  1.9304e-02, -1.1957e-01, -1.4818e-01,\n",
       "         -9.7831e-01, -5.8960e-02,  1.7460e-01, -2.0389e-01, -1.4001e-01,\n",
       "         -2.4887e-01, -1.1476e-01, -1.5955e-01,  2.1249e-01, -1.5593e-01,\n",
       "         -1.2544e-01, -9.8624e-01,  3.2594e-01,  4.3030e-01,  3.9739e-01,\n",
       "         -7.1544e-02,  5.5542e-02,  2.3614e-01,  5.1451e-02, -1.2712e-01,\n",
       "          1.2862e-01, -3.7288e-01, -1.7457e-01,  3.1211e-02,  3.1962e-01,\n",
       "         -1.1463e-01,  4.3707e-02, -5.4888e-02, -4.2289e-01,  2.1389e-02,\n",
       "          1.5016e-01,  1.2938e-01,  2.7528e-01,  1.6527e-01, -8.0278e-02,\n",
       "          2.2269e-01, -9.3583e-02,  2.0641e-01,  1.4012e-01, -1.2170e-01,\n",
       "         -4.7616e-02,  3.4851e-01,  1.4886e-01, -6.6527e-02, -1.5485e-01,\n",
       "         -2.8443e-01, -1.6935e-02, -1.1944e-01,  3.0073e-01, -2.4560e-02,\n",
       "         -1.5824e-01,  1.1635e-02, -1.3662e-01, -1.4565e-01, -2.2405e-01,\n",
       "         -3.3309e-02,  2.7077e-01, -2.3188e-01, -6.1099e-02, -1.2465e-01,\n",
       "         -1.8577e-01, -3.4382e-01, -2.9314e-01, -3.0381e-01,  4.8681e-02,\n",
       "         -1.6708e-02,  1.8832e-01, -4.0353e-01,  7.1195e-02, -2.0810e-01,\n",
       "          2.8431e-01,  1.3518e-01,  2.9105e-01,  2.7376e-01, -1.0368e-01,\n",
       "         -7.4605e-02, -3.6850e-01,  5.7559e-02, -1.1951e-01, -5.0005e-01,\n",
       "          1.2482e-01,  3.2667e-02, -2.2467e-01, -3.7686e-01, -2.2807e-01,\n",
       "         -1.7667e-01, -2.3786e-01,  1.0026e-02,  8.0749e-02,  2.0454e-01,\n",
       "          8.8677e-02,  2.7418e-03,  1.4690e-02,  3.5927e-02,  6.7707e-02,\n",
       "          3.5276e-01, -1.8516e-01,  4.4570e-02, -2.2667e-01, -3.6075e-01,\n",
       "         -4.1719e-01,  9.7958e-01, -3.2338e-01, -5.0447e-02, -7.8756e-02,\n",
       "          6.8711e-03, -2.7125e-01,  5.4918e-02,  1.5848e-01,  2.0574e-02,\n",
       "          1.6751e-01, -9.4175e-02, -3.3342e-01,  2.3498e-02, -2.2682e-01,\n",
       "         -3.3259e-01, -1.3691e-01,  3.2090e-01, -4.2446e-01, -2.8447e-02,\n",
       "          9.2432e-02,  6.7216e-02, -3.3666e-02,  6.6909e-02, -9.1077e-03,\n",
       "         -1.6084e-01,  5.1560e-01, -9.5232e-02,  9.7539e-01,  3.8330e-01,\n",
       "         -3.2164e-02, -1.8377e-01,  3.2245e-01, -2.4034e-01,  5.3319e-04,\n",
       "         -1.3715e-01, -9.2167e-02, -2.2548e-01,  1.8458e-01,  3.2771e-01,\n",
       "         -1.4221e-01,  3.0665e-01, -3.7137e-04,  3.0886e-02,  2.0629e-01,\n",
       "         -2.9112e-01,  2.4382e-01,  6.6053e-02, -2.7433e-01, -6.7446e-02,\n",
       "          1.2967e-01,  3.8533e-01,  3.1656e-01, -1.9511e-01,  6.9938e-02,\n",
       "          3.5475e-02, -9.5249e-02,  1.0071e-02,  4.8055e-03,  2.2542e-01,\n",
       "          9.7661e-02,  1.0126e-01, -3.5655e-01,  1.1394e-01, -2.0782e-01,\n",
       "         -3.7452e-01, -7.3282e-02, -8.4066e-02,  8.8500e-02,  8.3590e-02,\n",
       "         -1.9186e-01,  1.3659e-03, -3.0616e-01,  1.9825e-02,  6.8391e-02,\n",
       "          1.0706e-01, -4.2666e-01, -2.8942e-02,  2.7085e-01,  3.3830e-01,\n",
       "         -9.5545e-02, -1.3901e-01,  7.7556e-02,  1.3687e-02, -2.1426e-01,\n",
       "         -5.8842e-01,  1.5825e-01, -8.3859e-02,  3.3314e-01, -7.5194e-02,\n",
       "         -4.3461e-02, -3.5593e-01,  4.0472e-01,  4.4127e-02,  4.1913e-02,\n",
       "          1.7226e-01,  1.3777e-01, -4.6696e-01,  3.2325e-01,  2.4491e-01,\n",
       "          2.4346e-01, -1.5675e-01, -2.8011e-01, -2.8930e-01,  2.7583e-01,\n",
       "         -1.6524e-01,  1.0357e-01, -6.6242e-02,  2.4517e-01, -3.4259e-01,\n",
       "          2.5226e-01, -1.2221e-01, -5.8934e-02,  3.2027e-01, -2.1643e-02,\n",
       "          4.6745e-01, -5.5477e-02, -8.0470e-02, -1.1880e-01, -4.6031e-02,\n",
       "          2.6844e-02,  6.5898e-02, -6.0981e-02,  5.8301e-01,  7.5551e-02,\n",
       "         -4.2353e-01,  1.0435e-01,  2.2959e-01,  1.1113e-01, -6.8913e-02,\n",
       "          1.6286e-01, -1.4719e-01,  2.2429e-01,  1.0481e-01,  1.8677e-01,\n",
       "         -9.7800e-01, -3.7530e-02, -4.8489e-02,  2.9654e-01, -1.5475e-01,\n",
       "         -9.8986e-03,  1.5777e-01, -1.9469e-02,  1.4547e-01,  1.9087e-01,\n",
       "         -2.3728e-01, -1.0693e-01,  4.7741e-02, -5.2418e-01,  4.1395e-02,\n",
       "         -1.3499e-01, -2.4859e-01,  7.2289e-02,  3.7036e-02, -1.4449e-01,\n",
       "          2.3209e-01, -5.7132e-02, -5.3320e-01,  2.7887e-01,  4.2062e-02,\n",
       "          6.0053e-02, -2.1927e-01,  1.5334e-02, -9.8084e-01, -6.7554e-02,\n",
       "         -2.9982e-01, -1.3481e-01,  2.6833e-02, -1.4651e-01, -3.6421e-02,\n",
       "         -1.1051e-01,  1.3752e-01,  1.5979e-01, -1.7008e-04, -3.2802e-01,\n",
       "          2.0466e-01, -1.6546e-01, -1.5611e-01,  1.5391e-01,  4.0601e-02,\n",
       "          5.4587e-01,  1.8482e-01, -1.1463e-01,  3.2847e-01,  2.4080e-01,\n",
       "          1.1909e-01, -4.7140e-01,  1.8072e-03,  4.1957e-01,  2.2770e-02,\n",
       "         -2.8297e-01, -1.5603e-02,  2.3007e-01, -4.1853e-01,  3.2141e-01,\n",
       "          3.0646e-04, -3.8443e-02,  1.6472e-02,  5.8907e-02, -5.0399e-02,\n",
       "          1.7465e-01, -2.3205e-01, -1.9567e-01,  9.8331e-01,  1.9351e-01,\n",
       "         -6.4504e-02, -8.0574e-02,  6.9706e-02,  5.7410e-01, -2.1200e-01,\n",
       "         -2.0317e-01,  3.3102e-02,  1.7879e-01,  2.0866e-01, -1.2587e-01,\n",
       "         -2.3790e-01, -2.7158e-01, -2.8333e-02, -2.1295e-02,  5.2025e-02,\n",
       "         -9.6668e-02, -2.6422e-01,  5.9902e-04,  2.2742e-01, -2.2203e-01,\n",
       "         -4.3099e-02,  1.2703e-01, -1.6265e-02, -3.1125e-01, -2.1679e-01,\n",
       "          2.5297e-01,  1.1954e-01,  1.1920e-01, -2.1771e-02, -1.5300e-01,\n",
       "          7.3958e-02,  1.8506e-01, -2.4456e-02, -2.2490e-01, -1.6262e-01,\n",
       "         -1.2869e-01,  2.0625e-03,  1.7954e-01,  8.9647e-02, -1.4530e-01,\n",
       "         -9.6349e-02,  2.2362e-01,  2.6965e-01,  5.9118e-02, -3.1305e-01,\n",
       "          2.9986e-01, -9.8264e-01,  3.7083e-01,  1.5982e-01, -1.6848e-01,\n",
       "          2.3371e-01, -1.3659e-01,  1.5134e-01,  2.1121e-01,  2.9058e-02,\n",
       "         -1.6380e-02,  2.1166e-02, -1.5863e-01,  1.7582e-01,  2.8560e-01,\n",
       "         -1.8570e-01,  3.4665e-01,  2.0629e-01, -1.9298e-02, -1.4730e-01,\n",
       "          3.4280e-04, -2.0731e-01, -1.1964e-01,  8.0838e-02, -6.0274e-02,\n",
       "         -1.6969e-01, -1.6707e-01,  3.7394e-01,  1.0651e-01, -2.2671e-02,\n",
       "          3.9144e-01, -1.0427e-01,  7.2137e-02,  2.4801e-01,  2.2152e-01,\n",
       "          2.4392e-01,  1.5137e-01,  3.3234e-01, -2.8788e-01,  5.0412e-01,\n",
       "          6.4060e-02,  1.7549e-01,  5.8653e-02,  2.0384e-02, -1.8081e-01,\n",
       "         -1.0022e-01, -2.3441e-01,  3.0298e-01, -2.1766e-01, -1.4679e-01,\n",
       "         -1.1829e-01,  9.8023e-01,  2.2004e-01,  2.2734e-01, -1.4599e-01,\n",
       "          2.4377e-02,  4.4948e-01,  1.8157e-02,  1.9906e-01, -2.8293e-02,\n",
       "          1.3537e-01,  2.2616e-01,  1.2952e-01, -5.6328e-02,  2.4090e-01,\n",
       "          1.5959e-01,  2.7432e-01,  1.8245e-01, -2.1436e-01,  7.4671e-03,\n",
       "         -2.2497e-01, -1.7068e-01, -5.5720e-01, -1.6737e-01,  4.0409e-01,\n",
       "         -1.0243e-01, -2.1573e-01,  1.1200e-01, -1.0675e-01, -1.3540e-01,\n",
       "          3.9332e-02,  1.9163e-01,  1.3452e-01, -1.3238e-01,  2.2138e-01,\n",
       "          5.2717e-02,  9.8148e-01, -3.2221e-01,  6.6462e-03,  2.3761e-01,\n",
       "         -3.3691e-02,  3.4261e-03,  4.2259e-02,  5.9366e-02,  3.1588e-01,\n",
       "         -3.1106e-02,  4.4349e-02, -2.4874e-01,  2.2648e-01,  9.2131e-02,\n",
       "          2.9647e-02,  9.0583e-02,  2.1838e-01,  4.4654e-02,  1.2244e-01,\n",
       "          2.7379e-01, -3.8186e-01, -1.2864e-01,  5.6164e-02, -1.7028e-01,\n",
       "          2.6292e-01,  9.4479e-02, -2.6772e-01, -1.6571e-01, -4.6017e-02,\n",
       "         -1.1116e-01,  2.2867e-01, -3.1004e-02,  1.1613e-01, -6.8305e-02,\n",
       "          1.6451e-01, -1.4420e-01,  1.7088e-01, -2.3379e-01,  9.8009e-01,\n",
       "          3.1621e-02,  1.3900e-01, -1.9217e-01,  2.1153e-02, -1.7689e-01,\n",
       "          1.3814e-01,  3.4596e-01, -1.4792e-01,  2.7178e-01,  2.4310e-01,\n",
       "         -3.3192e-01,  2.2116e-01,  2.2839e-02, -6.3564e-01,  7.7178e-02,\n",
       "          1.2285e-01, -2.0654e-01,  3.8014e-01,  4.0526e-01,  9.2871e-03,\n",
       "         -5.1818e-03, -2.2081e-01,  1.1172e-01,  2.6532e-01,  8.1269e-02,\n",
       "         -2.5537e-01,  2.7313e-01, -2.6605e-01, -3.1805e-01, -2.2874e-01,\n",
       "          9.8547e-01,  9.8442e-01, -7.4923e-02,  3.1742e-01, -3.2054e-02,\n",
       "         -1.3206e-01, -1.1249e-01, -2.5681e-01, -2.1065e-02,  1.5215e-01,\n",
       "          2.9338e-02, -9.7367e-02, -2.9898e-01,  1.0663e-01,  9.1909e-02,\n",
       "          7.9451e-02,  4.4742e-02,  1.8093e-01, -2.4898e-01,  2.3382e-01,\n",
       "          1.4006e-01,  1.2341e-01,  1.6822e-01,  1.7127e-01,  2.9047e-01,\n",
       "          1.6688e-01,  1.2612e-01,  1.1278e-01,  3.7214e-02,  9.3170e-02,\n",
       "         -3.6323e-01,  5.9252e-02, -9.7649e-01, -2.6150e-02,  1.6122e-02,\n",
       "         -5.7212e-02,  3.2720e-01, -7.9024e-02,  5.3491e-02, -1.5549e-01,\n",
       "         -3.5151e-02, -2.8966e-01,  1.8899e-01,  2.9783e-01,  1.5064e-02,\n",
       "          8.8466e-02,  3.2326e-03,  3.6980e-01, -9.2559e-02,  7.5636e-02,\n",
       "         -1.5970e-01,  1.6336e-01,  4.1741e-02, -1.0267e-01, -3.4059e-01,\n",
       "          8.5906e-02, -7.8138e-03, -1.2314e-01,  1.6253e-01, -6.4315e-02,\n",
       "         -2.1686e-01, -1.7217e-01,  1.0669e-01,  2.7152e-02, -1.9839e-01,\n",
       "          1.9449e-01, -1.1709e-01,  2.3073e-01,  2.3242e-02, -1.9597e-01,\n",
       "         -2.1234e-01, -2.2069e-01,  1.4413e-03, -3.6248e-02,  1.6393e-02,\n",
       "         -6.3046e-02,  9.7380e-02, -1.4925e-01, -1.6855e-01, -2.3429e-01,\n",
       "         -2.6608e-02,  7.5290e-02,  2.1086e-02,  2.7953e-01,  2.9158e-01,\n",
       "         -1.2548e-01,  4.4164e-01,  2.4020e-01, -6.1693e-01,  4.2223e-03,\n",
       "          9.8741e-01, -1.8165e-02, -2.3868e-01, -2.2423e-01,  1.0912e-01,\n",
       "          5.0101e-02, -6.8893e-02,  4.1577e-01,  2.4503e-01,  4.7381e-01,\n",
       "         -3.6586e-01,  1.6278e-01,  4.5695e-02,  2.8465e-01,  3.2346e-01,\n",
       "          3.9311e-03,  1.2960e-01,  2.9544e-01, -6.1812e-02,  3.1293e-01,\n",
       "          1.0534e-01,  2.6742e-02,  2.3464e-01,  3.0570e-01, -2.6347e-01,\n",
       "          3.7890e-01, -1.4563e-02, -2.4103e-01,  1.5129e-01, -1.9716e-01,\n",
       "          7.8148e-02,  1.5645e-01,  1.9982e-01, -3.7573e-01, -1.9815e-01,\n",
       "          3.1612e-02,  1.0912e-01, -2.3084e-01,  2.2709e-01,  1.6557e-01,\n",
       "          1.0918e-01,  1.2294e-01,  1.7126e-01,  2.2601e-01, -3.6356e-01,\n",
       "          1.5937e-01, -1.6891e-02, -4.0598e-01, -3.7272e-01, -8.4155e-02,\n",
       "          4.8069e-02, -3.4830e-01,  2.3817e-02, -3.2124e-01,  4.4253e-01,\n",
       "          9.3406e-02, -2.0233e-01,  1.7414e-01, -9.3432e-02,  1.9897e-01,\n",
       "          1.8952e-01, -2.5906e-01, -1.9305e-01, -9.8590e-01,  7.0064e-02,\n",
       "          3.7127e-01,  8.4209e-02, -2.9759e-01, -8.7342e-02, -2.2532e-02,\n",
       "          2.8501e-01,  1.8859e-01, -3.2663e-01,  2.2966e-02,  1.3241e-01,\n",
       "         -2.6598e-01, -3.4003e-02,  3.5191e-02, -2.4548e-01, -1.7298e-01,\n",
       "         -1.6462e-01,  1.3027e-01,  4.8564e-02, -2.6406e-02, -3.9528e-01,\n",
       "          1.7384e-01, -1.9038e-01, -6.0029e-02,  7.5644e-02, -1.1952e-01,\n",
       "         -8.1747e-02, -2.1441e-01, -9.1340e-02, -6.7001e-01, -2.9096e-01,\n",
       "         -1.1713e-01,  1.4229e-01,  1.6218e-01,  7.8249e-02,  1.9384e-01,\n",
       "          1.2514e-01,  2.2664e-01,  1.2273e-01,  3.6206e-03,  3.3050e-02,\n",
       "          1.5433e-01, -2.5490e-01,  3.1914e-01, -4.0160e-01,  1.4855e-01,\n",
       "          1.1823e-01,  7.5319e-02, -1.1803e-01, -2.7152e-02,  3.7218e-03,\n",
       "          9.9644e-04,  9.6357e-02,  1.6060e-01,  1.9067e-01,  3.7031e-02,\n",
       "         -1.5852e-01, -2.9057e-01, -6.7612e-02, -2.4767e-01,  1.8456e-01,\n",
       "         -5.0929e-01, -9.7098e-02, -2.6034e-01,  1.9318e-01,  2.6572e-01,\n",
       "         -2.0138e-01, -5.4560e-02, -2.7562e-01, -1.0375e-01,  7.6244e-02,\n",
       "          3.8144e-01,  2.2278e-01,  2.9371e-01,  3.0940e-01, -3.2791e-01,\n",
       "          9.9915e-02,  4.5474e-01,  2.0245e-01, -1.2807e-01, -8.3382e-02,\n",
       "          5.8737e-02,  6.7801e-01, -6.6836e-02,  6.7175e-02, -8.1270e-02,\n",
       "         -2.8477e-01,  1.8288e-01,  5.0438e-02]]), hidden_states=(tensor([[[-0.3829,  0.1298, -0.1524,  ...,  0.2827, -0.4924, -0.0289],\n",
       "         [ 0.6552,  0.7460,  0.2177,  ...,  0.3522,  0.1716, -0.9211],\n",
       "         [-0.4966,  0.9500,  0.0879,  ...,  0.5080, -0.1492, -0.5068],\n",
       "         [ 1.0208,  0.5376, -0.5549,  ..., -0.8845,  0.4662,  1.0258],\n",
       "         [ 0.6700,  1.0549,  0.8781,  ..., -0.0748,  1.1266, -0.0276]]]), tensor([[[-0.1144, -0.0678, -0.0593,  ...,  0.0556, -0.2215,  0.0952],\n",
       "         [ 0.5504,  0.3002, -0.1421,  ...,  0.8179, -0.0373, -1.2209],\n",
       "         [-0.3381,  0.1896,  0.4066,  ...,  0.5310, -0.5837, -0.0393],\n",
       "         [ 1.0348,  0.2874, -0.3798,  ..., -0.6595,  0.0789,  1.0706],\n",
       "         [ 0.8394,  0.7882,  0.5379,  ..., -0.1019,  0.8362, -0.1669]]]), tensor([[[-0.0540, -0.0576, -0.0015,  ...,  0.0199, -0.0633,  0.0801],\n",
       "         [ 1.1019, -0.2235,  0.2716,  ...,  1.3877,  0.4822, -0.9379],\n",
       "         [-0.5224, -0.1899,  0.6592,  ...,  0.6560, -0.1573, -0.2532],\n",
       "         [ 0.5412,  0.4249,  0.0361,  ..., -0.7275,  0.0236,  0.4458],\n",
       "         [ 0.4355,  0.6958,  0.4284,  ...,  0.1290,  0.2834,  0.0901]]]), tensor([[[-0.0357, -0.0217,  0.0470,  ...,  0.0085, -0.0352,  0.1625],\n",
       "         [ 0.7512, -0.0244,  0.4447,  ...,  1.3278,  0.2059, -0.9176],\n",
       "         [-0.3195, -0.7848,  0.4788,  ...,  1.0553, -0.0284, -0.3493],\n",
       "         [ 0.2050,  0.1669,  0.5988,  ..., -0.8527, -0.3299,  0.3128],\n",
       "         [ 0.3916,  0.9367,  0.3598,  ...,  0.2499,  0.0923,  0.4098]]]), tensor([[[ 0.0056,  0.0223,  0.0383,  ...,  0.0601,  0.0104,  0.1226],\n",
       "         [ 0.9647, -0.3606,  0.2066,  ...,  1.4562,  0.0887, -0.5186],\n",
       "         [-0.2248, -0.8469,  0.1152,  ...,  1.1824,  0.4760, -0.1624],\n",
       "         [ 0.3555, -0.0493,  0.5895,  ..., -0.9160, -0.1924,  0.3798],\n",
       "         [ 0.2616,  1.1535,  0.2477,  ...,  0.1714,  0.1580,  0.3842]]]), tensor([[[ 0.0671,  0.7013,  0.1244,  ...,  0.8350,  0.2232, -0.0632],\n",
       "         [ 1.3343, -0.1528,  0.2485,  ...,  1.5435,  0.3419, -0.0387],\n",
       "         [ 0.4436, -0.3563, -0.1334,  ...,  1.1551,  0.2949, -0.0125],\n",
       "         [ 0.5785,  0.6426,  0.6719,  ..., -0.4587, -0.2794,  0.2249],\n",
       "         [ 0.3390,  1.1946,  0.5058,  ...,  0.2644,  0.0428,  0.4797]]]), tensor([[[-0.0066,  1.2389, -0.3194,  ...,  2.0918,  1.0138,  0.6836],\n",
       "         [ 1.1809,  0.6468,  0.5448,  ...,  2.0076,  0.1493,  0.2700],\n",
       "         [ 0.8765,  0.4129,  0.1685,  ...,  1.4359,  0.2356,  0.3014],\n",
       "         [ 0.7605,  1.2451,  0.3717,  ..., -0.1937, -0.1163,  0.2525],\n",
       "         [ 0.3848,  1.5147,  0.6855,  ...,  0.8617,  0.0444,  0.7223]]]), tensor([[[ 0.0909,  0.7013, -0.1820,  ...,  2.0081,  1.4654,  0.4832],\n",
       "         [ 0.9342,  0.2749,  0.0607,  ...,  2.2067,  1.0474,  0.0026],\n",
       "         [ 0.5855,  0.2717,  0.1172,  ...,  1.3975,  1.0330,  0.1388],\n",
       "         [ 0.8607,  1.0579,  0.2142,  ...,  0.4756,  0.7384,  0.3141],\n",
       "         [ 0.2326,  0.8529,  0.5643,  ...,  0.7804,  1.0802,  0.5543]]]), tensor([[[ 0.8393,  0.6421,  0.2978,  ...,  1.4160,  1.2333, -0.3154],\n",
       "         [ 1.5406, -0.2512,  0.1964,  ...,  1.9922,  1.2115, -0.3103],\n",
       "         [ 1.0845,  0.0734,  0.0457,  ...,  1.4894,  0.9083, -0.6709],\n",
       "         [ 1.2872,  0.8275,  0.3301,  ...,  0.8835,  0.9459, -0.2212],\n",
       "         [ 1.0418,  0.4737,  0.8927,  ...,  0.3185,  1.1782, -0.0339]]]), tensor([[[ 0.4597, -0.0368, -0.5594,  ...,  1.6802,  1.6670, -0.2929],\n",
       "         [ 1.5071, -0.3836, -0.1404,  ...,  2.3439,  1.3481, -0.0821],\n",
       "         [ 0.9691,  0.2728, -0.3211,  ...,  1.8503,  0.8654, -0.3736],\n",
       "         [ 0.9935,  0.2413, -0.0767,  ...,  1.2325,  1.5644, -0.2785],\n",
       "         [ 0.6400,  0.0489,  0.4110,  ...,  0.6897,  1.7416, -0.0876]]]), tensor([[[ 0.6535,  0.1802, -0.1041,  ...,  1.6654,  1.2956,  0.4124],\n",
       "         [ 1.0370, -0.3778,  0.0149,  ...,  2.0677,  0.7888,  0.3621],\n",
       "         [ 1.2396,  0.2441, -0.0272,  ...,  1.7812,  0.4802, -0.3787],\n",
       "         [ 0.8757,  0.3466,  0.6289,  ...,  1.2643,  1.0921,  0.3266],\n",
       "         [ 0.6653,  0.2458,  0.5745,  ...,  0.8199,  1.1245,  0.4815]]]), tensor([[[ 0.9545,  0.0302,  0.4444,  ...,  1.8572,  0.8102,  0.1466],\n",
       "         [ 1.4603, -0.4048,  0.4206,  ...,  2.4258,  0.7152,  0.2534],\n",
       "         [ 1.5357,  0.3766,  0.7283,  ...,  2.0698,  0.3759, -0.4477],\n",
       "         [ 0.8860,  0.3440,  1.1369,  ...,  1.4862,  0.7333,  0.2088],\n",
       "         [ 1.0283,  0.1132,  1.0015,  ...,  1.2758,  0.5360,  0.2183]]]), tensor([[[ 0.3722, -0.2836,  0.2937,  ...,  0.6907,  0.2142,  0.2329],\n",
       "         [ 0.3534, -0.5321,  0.2235,  ...,  1.0148,  0.1673,  0.2986],\n",
       "         [ 0.6164, -0.2585,  0.7959,  ...,  0.7183, -0.1231, -0.1010],\n",
       "         [ 0.3348, -0.2729,  0.5100,  ...,  0.6602,  0.1632,  0.2698],\n",
       "         [ 0.4161, -0.2375,  0.4754,  ...,  0.4744,  0.0905,  0.2347]]])), past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1722 1722\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = []\n",
    "for i, output in enumerate(outputs):\n",
    "    if i % 100 == 0: print(i)\n",
    "    # Concatenate the tensors for all layers. We use `stack` here to\n",
    "    # create a new dimension in the tensor.\n",
    "    token_embeddings = torch.stack(output[2], dim=0)\n",
    "    \n",
    "    # Remove dimension 1, the \"batches\".\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    \n",
    "    # Swap dimensions 0 and 1.\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "    all_embeddings.append(token_embeddings)\n",
    "\n",
    "print(len(sentences), len(all_embeddings))\n",
    "for i in range(len(sentences)):\n",
    "    if len(sentences[i]) != len(all_embeddings[i]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n"
     ]
    }
   ],
   "source": [
    "cur_word_length = 0\n",
    "concatenated_embeddings = []\n",
    "for i, token_embeddings in enumerate(all_embeddings):\n",
    "    # Stores the token vectors, with shape [22 x 3,072]\n",
    "    token_vecs_cat = {}\n",
    "    if i % 100 == 0: print(i)\n",
    "\n",
    "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "    # print(token_embeddings.size())\n",
    "\n",
    "    # For each token in the sentence...\n",
    "    length = 0\n",
    "    for j, token in enumerate(token_embeddings):\n",
    "\n",
    "        # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        \n",
    "        # Sum the vectors from the last four layers.\n",
    "        # sum_vec = torch.sum(token[-4:], dim=0)\n",
    "\n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        if j == 0:\n",
    "            token_vecs_cat[length] = [cat_vec, sentences[i][j]]\n",
    "        elif sentences[i][j].startswith('##'):\n",
    "            length += len(sentences[i][j]) - 2\n",
    "        else:\n",
    "            token_vecs_cat[length] = [cat_vec, sentences[i][j]]\n",
    "            length += len(sentences[i][j])\n",
    "    \n",
    "    concatenated_embeddings.append(token_vecs_cat)\n",
    "\n",
    "#     print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(concatenated_embeddings, 'embeddings.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_embeddings = torch.load('embeddings.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]']\n",
      "[0, 3, 7, 11, 13, 17, 20, 24, 26, 29, 31, 35, 40, 43, 48, 49, 53, 56, 58, 61, 64, 67, 72, 73]\n",
      "['तेरे', 'Possessor', 'Possessor', 96, 44]\n",
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]']\n",
      "[0, 3, 7, 11, 13, 17, 20, 24, 26, 29, 31, 35, 40, 43, 48, 49, 53, 56, 58, 61, 64, 67, 72, 73]\n",
      "['के', 'Beneficiary', 'Beneficiary', 96, 51]\n",
      "['[CLS]', 'इसी', 'तरह', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'ती', '##सर', '##े', 'दिन', 'म', '##ु', '##झ', '##े', 'ब', '##ा', '##ओ', '##बा', '##ब', '[UNK]', '(', 'ग', '##ोर', '##ख', '##च', '##िं', '##च', ')', 'नामक', 'प', '##ेड', '##़', 'के', 'लगा', '##ता', '##र', 'ब', '##ढ़', '##ने', ',', 'फ', '##ै', '##लन', '##े', 'और', 'उस', '##से', 'उत्पन्न', 'ख', '##तर', '##े', 'के', 'बारे', 'में', 'पता', 'च', '##ला', '-', 'और', 'यह', 'भी', 'भ', '##ेड', '##़', 'की', 'ही', 'व', '##ज', '##ह', 'से', 'क्योंकि', 'उसने', 'म', '##ु', '##झ', '##से', 'अ', '##चा', '##नक', 'इस', 'तरह', 'पू', '##छ', '##ा', 'जैसे', 'उसे', 'कोई', 'बड़ी', 'श', '##ंका', 'हो', '।', '[SEP]']\n",
      "[0, 3, 6, 14, 16, 23, 25, 30, 33, 37, 43, 48, 49, 57, 58, 62, 66, 68, 74, 79, 80, 85, 87, 91, 98, 102, 104, 108, 111, 114, 117, 118, 120, 122, 124, 128, 130, 132, 135, 137, 144, 148, 153, 158, 160, 163, 167, 171, 174, 177, 181, 185, 187, 188]\n",
      "['उससे', 'Source', 'Source', 104, 83]\n",
      "['[CLS]', 'इसी', 'तरह', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'ती', '##सर', '##े', 'दिन', 'म', '##ु', '##झ', '##े', 'ब', '##ा', '##ओ', '##बा', '##ब', '[UNK]', '(', 'ग', '##ोर', '##ख', '##च', '##िं', '##च', ')', 'नामक', 'प', '##ेड', '##़', 'के', 'लगा', '##ता', '##र', 'ब', '##ढ़', '##ने', ',', 'फ', '##ै', '##लन', '##े', 'और', 'उस', '##से', 'उत्पन्न', 'ख', '##तर', '##े', 'के', 'बारे', 'में', 'पता', 'च', '##ला', '-', 'और', 'यह', 'भी', 'भ', '##ेड', '##़', 'की', 'ही', 'व', '##ज', '##ह', 'से', 'क्योंकि', 'उसने', 'म', '##ु', '##झ', '##से', 'अ', '##चा', '##नक', 'इस', 'तरह', 'पू', '##छ', '##ा', 'जैसे', 'उसे', 'कोई', 'बड़ी', 'श', '##ंका', 'हो', '।', '[SEP]']\n",
      "[0, 3, 6, 14, 16, 23, 25, 30, 33, 37, 43, 48, 49, 57, 58, 62, 66, 68, 74, 79, 80, 85, 87, 91, 98, 102, 104, 108, 111, 114, 117, 118, 120, 122, 124, 128, 130, 132, 135, 137, 144, 148, 153, 158, 160, 163, 167, 171, 174, 177, 181, 185, 187, 188]\n",
      "['उसने', 'Originator', 'Agent', 104, 140]\n",
      "['[CLS]', ',', ',', ',', ',', ',', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##े', 'जो', 'ब', '##क्स', '##ा', 'दिया', 'है', 'उस', '##में', 'एक', 'अ', '##च्छा', '##ई', 'है', '-', 'र', '##ात', 'को', 'वह', 'मे', '##री', 'भ', '##ेड', '##़', 'के', 'लिए', 'घर', 'का', 'काम', 'दे', '##गा', '।', '[SEP]']\n",
      "[0, 1, 2, 3, 4, 5, 9, 13, 15, 20, 24, 26, 31, 33, 39, 41, 42, 45, 47, 49, 53, 57, 59, 62, 64, 66, 69, 73, 74]\n",
      "['मुझे', 'Recipient', 'Recipient', 302, 10]\n",
      "['[CLS]', ',', ',', ',', ',', ',', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##े', 'जो', 'ब', '##क्स', '##ा', 'दिया', 'है', 'उस', '##में', 'एक', 'अ', '##च्छा', '##ई', 'है', '-', 'र', '##ात', 'को', 'वह', 'मे', '##री', 'भ', '##ेड', '##़', 'के', 'लिए', 'घर', 'का', 'काम', 'दे', '##गा', '।', '[SEP]']\n",
      "[0, 1, 2, 3, 4, 5, 9, 13, 15, 20, 24, 26, 31, 33, 39, 41, 42, 45, 47, 49, 53, 57, 59, 62, 64, 66, 69, 73, 74]\n",
      "['उसमें', 'Gestalt', 'Locus', 302, 27]\n",
      "['[CLS]', ',', ',', ',', ',', ',', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##े', 'जो', 'ब', '##क्स', '##ा', 'दिया', 'है', 'उस', '##में', 'एक', 'अ', '##च्छा', '##ई', 'है', '-', 'र', '##ात', 'को', 'वह', 'मे', '##री', 'भ', '##ेड', '##़', 'के', 'लिए', 'घर', 'का', 'काम', 'दे', '##गा', '।', '[SEP]']\n",
      "[0, 1, 2, 3, 4, 5, 9, 13, 15, 20, 24, 26, 31, 33, 39, 41, 42, 45, 47, 49, 53, 57, 59, 62, 64, 66, 69, 73, 74]\n",
      "['को', 'Time', 'Time', 302, 46]\n",
      "['[CLS]', ',', ',', ',', ',', ',', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##े', 'जो', 'ब', '##क्स', '##ा', 'दिया', 'है', 'उस', '##में', 'एक', 'अ', '##च्छा', '##ई', 'है', '-', 'र', '##ात', 'को', 'वह', 'मे', '##री', 'भ', '##ेड', '##़', 'के', 'लिए', 'घर', 'का', 'काम', 'दे', '##गा', '।', '[SEP]']\n",
      "[0, 1, 2, 3, 4, 5, 9, 13, 15, 20, 24, 26, 31, 33, 39, 41, 42, 45, 47, 49, 53, 57, 59, 62, 64, 66, 69, 73, 74]\n",
      "['के', 'Beneficiary', 'Beneficiary', 302, 58]\n",
      "['[CLS]', ',', ',', ',', ',', ',', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##े', 'जो', 'ब', '##क्स', '##ा', 'दिया', 'है', 'उस', '##में', 'एक', 'अ', '##च्छा', '##ई', 'है', '-', 'र', '##ात', 'को', 'वह', 'मे', '##री', 'भ', '##ेड', '##़', 'के', 'लिए', 'घर', 'का', 'काम', 'दे', '##गा', '।', '[SEP]']\n",
      "[0, 1, 2, 3, 4, 5, 9, 13, 15, 20, 24, 26, 31, 33, 39, 41, 42, 45, 47, 49, 53, 57, 59, 62, 64, 66, 69, 73, 74]\n",
      "['का', 'Gestalt', 'Gestalt', 302, 65]\n",
      "['[CLS]', 'लेकिन', 'कुछ', 'असा', '##ध', '##रण', 'घ', '##ट', 'गया', 'कि', 'म', '##ैं', '##ने', 'जो', 'जा', '##बा', 'बनाया', 'था', 'उसकी', 'भ', '##ेड', '##़', 'के', 'लिए', 'उन', '##में', 'म', '##ैं', 'च', '##म', '##ड़े', 'की', 'प', '##ट', '##्टी', 'लगा', '##ना', 'भ', '##ूल', 'गया', 'था', '।', '[SEP]']\n",
      "[0, 5, 8, 14, 16, 19, 21, 26, 28, 32, 37, 42, 44, 48, 52, 54, 57, 62, 65, 70, 72, 77, 82, 85, 88, 90, 91]\n",
      "['उसकी', 'Possessor', 'Possessor', 999, 39]\n",
      "['[CLS]', 'लेकिन', 'कुछ', 'असा', '##ध', '##रण', 'घ', '##ट', 'गया', 'कि', 'म', '##ैं', '##ने', 'जो', 'जा', '##बा', 'बनाया', 'था', 'उसकी', 'भ', '##ेड', '##़', 'के', 'लिए', 'उन', '##में', 'म', '##ैं', 'च', '##म', '##ड़े', 'की', 'प', '##ट', '##्टी', 'लगा', '##ना', 'भ', '##ूल', 'गया', 'था', '।', '[SEP]']\n",
      "[0, 5, 8, 14, 16, 19, 21, 26, 28, 32, 37, 42, 44, 48, 52, 54, 57, 62, 65, 70, 72, 77, 82, 85, 88, 90, 91]\n",
      "['के', 'Recipient', 'Beneficiary', 999, 47]\n"
     ]
    }
   ],
   "source": [
    "for _, i in enumerate(data):\n",
    "    if i[4] not in concatenated_embeddings[i[3]]:\n",
    "        print(sentences[i[3]])\n",
    "        print([i for i in concatenated_embeddings[i[3]]])\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ca0007e4e422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate the cosine similarity between the word bank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# in \"bank robber\" vs \"bank vault\" (same meaning).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdiff_bank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenated_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Vector similarity for  *similar*  meanings:  %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msame_bank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "same_bank = 1 - cosine(concatenated_embeddings[14][6][0], concatenated_embeddings[14][11][0])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "diff_bank = 1 - cosine(concatenated_embeddings[14][6][0], concatenated_embeddings[14][3][0])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)\n",
    "\n",
    "diff_bank = 1 - cosine(concatenated_embeddings[4][11][0], concatenated_embeddings[10][1][0])\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450 1722\n",
      "['मैंने', 'Experiencer', 'Agent', 2, 0]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'ते', '##रा', 'जीवन', ',', 'उसकी', 'उ', '##दा', '##सी', 'ध', '##ीर', '##े', '-', 'ध', '##ीर', '##े', 'स', '##म', '##झ', 'ली', 'थी', '[SEP]'] ['मैंने', 'Experiencer', 'Agent', 2, 0]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'ते', '##रा', 'जीवन', ',', 'उसकी', 'उ', '##दा', '##सी', 'ध', '##ीर', '##े', '-', 'ध', '##ीर', '##े', 'स', '##म', '##झ', 'ली', 'थी', '[SEP]'] ['तेरा', 'Theme', 'Theme', 2, 5]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'ते', '##रा', 'जीवन', ',', 'उसकी', 'उ', '##दा', '##सी', 'ध', '##ीर', '##े', '-', 'ध', '##ीर', '##े', 'स', '##म', '##झ', 'ली', 'थी', '[SEP]'] ['उसकी', 'Gestalt', 'Gestalt', 2, 14]\n",
      "['[CLS]', 'बहुत', 'दिन', '##ों', 'तक', 'मे', '##रे', 'पास', 'म', '##न', 'ब', '##ह', '##ला', '##ने', 'का', 'एक', 'मात्रा', 'स', '##ा', '##धन', 'था', 'स', '##ूर', '##्यास', '##्त', 'का', 'स', '##ौ', '##ंदर', '##्य', '।', '[SEP]'] ['तक', 'Duration', 'EndTime', 3, 9]\n",
      "['[CLS]', 'बहुत', 'दिन', '##ों', 'तक', 'मे', '##रे', 'पास', 'म', '##न', 'ब', '##ह', '##ला', '##ने', 'का', 'एक', 'मात्रा', 'स', '##ा', '##धन', 'था', 'स', '##ूर', '##्यास', '##्त', 'का', 'स', '##ौ', '##ंदर', '##्य', '।', '[SEP]'] ['मेरे', 'Possessor', 'Possessor', 3, 11]\n",
      "['[CLS]', 'बहुत', 'दिन', '##ों', 'तक', 'मे', '##रे', 'पास', 'म', '##न', 'ब', '##ह', '##ला', '##ने', 'का', 'एक', 'मात्रा', 'स', '##ा', '##धन', 'था', 'स', '##ूर', '##्यास', '##्त', 'का', 'स', '##ौ', '##ंदर', '##्य', '।', '[SEP]'] ['का', 'Purpose', 'Purpose', 3, 26]\n",
      "['[CLS]', 'बहुत', 'दिन', '##ों', 'तक', 'मे', '##रे', 'पास', 'म', '##न', 'ब', '##ह', '##ला', '##ने', 'का', 'एक', 'मात्रा', 'स', '##ा', '##धन', 'था', 'स', '##ूर', '##्यास', '##्त', 'का', 'स', '##ौ', '##ंदर', '##्य', '।', '[SEP]'] ['का', 'Gestalt', 'Gestalt', 3, 51]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['इसका', 'Topic', 'Topic', 4, 0]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['मुझे', 'Recipient', 'Recipient', 4, 7]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['तुझसे', 'Agent', 'Ancillary', 4, 11]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['के', 'QuantityItem', 'Whole', 4, 23]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['तूने', 'Originator', 'Agent', 4, 37]\n",
      "['[CLS]', 'इसका', 'पता', 'म', '##ु', '##झ', '##े', 'त', '##ु', '##झ', '##से', 'म', '##ुल', '##ा', '##का', '##त', 'के', 'च', '##ौ', '##थे', 'दिन', 'च', '##ला', 'जब', 'त', '##ून', '##े', 'म', '##ु', '##झ', '##से', 'कहा', ':', '[SEP]'] ['मुझसे', 'Recipient', 'Ancillary', 4, 41]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'स', '##ूर', '##्यास', '##्त', 'बहुत', 'अ', '##च्छा', 'ल', '##गत', '##ा', 'है', '।', '[SEP]'] ['मुझे', 'Experiencer', 'Recipient', 5, 0]\n",
      "['[CLS]', 'लेकिन', 'उसके', 'लिए', 'तो', 'अ', '##भी', 'इ', '##ंत', '##जार', 'करना', 'होगा', '।', '[SEP]'] ['उसके', 'Purpose', 'Purpose', 7, 5]\n",
      "['[CLS]', 'इ', '##ंत', '##जार', ',', 'इ', '##ंत', '##जार', 'कि', '##स', 'बात', 'का', '?', '[SEP]'] ['का?', 'Purpose', 'Purpose', 8, 19]\n",
      "['[CLS]', 'त', '##ु', '##झ', '##े', 'बड़ा', 'आ', '##श', '##्', '##च', '##र', '##्य', 'था', '।', '[SEP]'] ['तुझे', 'Experiencer', 'Recipient', 10, 0]\n",
      "['[CLS]', 'त', '##ू', 'अपने', 'में', 'ह', '##ंस', '##ता', 'हुआ', 'ब', '##ोल', '##ा', 'था', '।', '[SEP]'] ['में', 'Manner', 'Manner', 11, 6]\n",
      "['[CLS]', 'म', '##ैं', 'स', '##ो', '##च', 'रहा', 'था', 'कि', 'म', '##ैं', 'अपने', 'घर', 'ह', '##ू', '##ं', '।', '[SEP]'] ['अपने', 'Possessor', 'Possessor', 13, 16]\n",
      "['[CLS]', 'वा', '##स्त', '##व', 'में', 'जब', 'अमेरिका', 'में', 'दो', '##प', '##हर', 'हो', 'तो', 'फ', '##्रा', '##ंस', 'में', 'स', '##ूर', '##्यास', '##्त', 'हो', 'रहा', 'होता', 'है', '।', '[SEP]'] ['में', 'Circumstance', 'Circumstance', 14, 6]\n",
      "['[CLS]', 'वा', '##स्त', '##व', 'में', 'जब', 'अमेरिका', 'में', 'दो', '##प', '##हर', 'हो', 'तो', 'फ', '##्रा', '##ंस', 'में', 'स', '##ूर', '##्यास', '##्त', 'हो', 'रहा', 'होता', 'है', '।', '[SEP]'] ['में', 'Locus', 'Locus', 14, 18]\n",
      "['[CLS]', 'वा', '##स्त', '##व', 'में', 'जब', 'अमेरिका', 'में', 'दो', '##प', '##हर', 'हो', 'तो', 'फ', '##्रा', '##ंस', 'में', 'स', '##ूर', '##्यास', '##्त', 'हो', 'रहा', 'होता', 'है', '।', '[SEP]'] ['में', 'Locus', 'Locus', 14, 36]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'अ', '##म', '##री', '##का', 'से', 'त', '##ुर', '##ंत', 'फ', '##्रा', '##ंस', 'प', '##ह', '##ु', '##ंच', 'जा', '##ए', 'तो', 'दो', '##प', '##हर', 'के', 'फ', '##ौर', '##न', 'बाद', 'श', '##ाम', 'दे', '##ख', 'सकता', 'है', '।', '[SEP]'] ['से', 'Source', 'Source', 15, 12]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'अ', '##म', '##री', '##का', 'से', 'त', '##ुर', '##ंत', 'फ', '##्रा', '##ंस', 'प', '##ह', '##ु', '##ंच', 'जा', '##ए', 'तो', 'दो', '##प', '##हर', 'के', 'फ', '##ौर', '##न', 'बाद', 'श', '##ाम', 'दे', '##ख', 'सकता', 'है', '।', '[SEP]'] ['के', 'Time', 'Time', 15, 40]\n",
      "['[CLS]', 'दु', '##र', '##्भ', '##ाग', '##्य', '##व', '##श', 'दोनों', 'के', 'बीच', 'की', 'दूर', '##ी', 'काफी', 'है', '।', '[SEP]'] ['के', 'Locus', 'Whole', 16, 16]\n",
      "['[CLS]', 'दु', '##र', '##्भ', '##ाग', '##्य', '##व', '##श', 'दोनों', 'के', 'बीच', 'की', 'दूर', '##ी', 'काफी', 'है', '।', '[SEP]'] ['की', 'Gestalt', 'Gestalt', 16, 21]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['तेरी', 'Gestalt', 'Gestalt', 17, 5]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['पर', 'Locus', 'Locus', 17, 19]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['तुझे', 'Agent', 'Agent', 17, 21]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['अपनी', 'Possessor', 'Possessor', 17, 27]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['की', 'Theme', 'Theme', 17, 56]\n",
      "['[CLS]', 'लेकिन', 'ते', '##री', 'छ', '##ोटी', 'सी', 'ध', '##रत', '##ी', 'पर', 'त', '##ु', '##झ', '##े', 'ब', '##स', 'अपनी', 'क', '##ुर', '##्स', '##ी', 'थ', '##ोड़', '##ी', 'इ', '##ध', '##र', '-', 'उ', '##ध', '##र', 'ख', '##िस', '##का', '##ने', 'की', 'ज', '##र', '##ूर', '##त', 'होती', 'हो', '##गी', 'और', 'त', '##ू', 'ज', '##ित', '##नी', 'बार', 'च', '##ाह', '##े', 'स', '##ूर', '##ज', 'का', 'ड', '##ू', '##ब', '##ना', 'दे', '##ख', 'सकता', 'होगा', '।', '[SEP]'] ['का', 'Theme', 'Theme', 17, 91]\n",
      "['[CLS]', 'एक', 'दिन', 'म', '##ैं', '##ने', 'त', '##ैं', '##ताल', '##िस', 'बार', 'स', '##ूर', '##्यास', '##्त', 'देखा', 'था', '।', '[SEP]'] ['मैंने', 'Experiencer', 'Agent', 18, 5]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'कहा', ',', '[SEP]'] ['मैंने', 'Originator', 'Agent', 21, 0]\n",
      "['[CLS]', 'तो', 'जिस', 'दिन', 'त', '##ून', '##े', 'त', '##ैं', '##ताल', '##िस', 'बार', 'स', '##ूर', '##्यास', '##्त', 'देखा', 'त', '##ू', 'बड़ा', 'उ', '##दा', '##स', 'रहा', 'होगा', '?', '[SEP]'] ['तूने', 'Experiencer', 'Agent', 22, 8]\n",
      "['[CLS]', 'लेकिन', 'उसने', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', 'प', '##ा', '##ंच', '##वे', 'दिन', ',', 'स', '##दा', 'की', 'तरह', 'भ', '##ेड', '##़', 'की', 'क', '##ृ', '##पा', 'से', 'ही', ',', 'न', '##न्', '##हे', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'के', 'एक', 'और', 'र', '##ह', '##स', '##्य', 'का', 'पता', 'च', '##ला', '।', '[SEP]'] ['उसने', 'Originator', 'Agent', 23, 5]\n",
      "['[CLS]', 'लेकिन', 'उसने', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', 'प', '##ा', '##ंच', '##वे', 'दिन', ',', 'स', '##दा', 'की', 'तरह', 'भ', '##ेड', '##़', 'की', 'क', '##ृ', '##पा', 'से', 'ही', ',', 'न', '##न्', '##हे', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'के', 'एक', 'और', 'र', '##ह', '##स', '##्य', 'का', 'पता', 'च', '##ला', '।', '[SEP]'] ['की', 'ComparisonRef', 'ComparisonRef', 24, 35]\n",
      "['[CLS]', 'लेकिन', 'उसने', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', 'प', '##ा', '##ंच', '##वे', 'दिन', ',', 'स', '##दा', 'की', 'तरह', 'भ', '##ेड', '##़', 'की', 'क', '##ृ', '##पा', 'से', 'ही', ',', 'न', '##न्', '##हे', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'के', 'एक', 'और', 'र', '##ह', '##स', '##्य', 'का', 'पता', 'च', '##ला', '।', '[SEP]'] ['की', 'Explanation', 'Explanation', 24, 44]\n",
      "['[CLS]', 'लेकिन', 'उसने', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', 'प', '##ा', '##ंच', '##वे', 'दिन', ',', 'स', '##दा', 'की', 'तरह', 'भ', '##ेड', '##़', 'की', 'क', '##ृ', '##पा', 'से', 'ही', ',', 'न', '##न्', '##हे', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'के', 'एक', 'और', 'र', '##ह', '##स', '##्य', 'का', 'पता', 'च', '##ला', '।', '[SEP]'] ['के', 'Topic', 'Topic', 24, 68]\n",
      "['[CLS]', 'लेकिन', 'उसने', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', 'प', '##ा', '##ंच', '##वे', 'दिन', ',', 'स', '##दा', 'की', 'तरह', 'भ', '##ेड', '##़', 'की', 'क', '##ृ', '##पा', 'से', 'ही', ',', 'न', '##न्', '##हे', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'के', 'एक', 'और', 'र', '##ह', '##स', '##्य', 'का', 'पता', 'च', '##ला', '।', '[SEP]'] ['का', 'Topic', 'Topic', 24, 79]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['जैसे', 'Time', 'Time', 25, 0]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['पर', 'Topic', 'Topic', 25, 16]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['से', 'Duration', 'StartTime', 25, 31]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['उसने', 'Originator', 'Agent', 25, 46]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['बिना', 'Manner', 'Manner', 25, 50]\n",
      "['[CLS]', 'जैसे', 'वह', 'किसी', 'स', '##म', '##स', '##्या', 'पर', 'च', '##ु', '##प', '##चा', '##प', 'बहुत', 'दे', '##र', 'से', 'विचार', 'कर', 'रहा', 'हो', ',', 'उसने', 'बिना', 'किसी', 'भूमिका', 'के', 'झ', '##ट', 'से', 'कहा', ',', '[SEP]'] ['से', 'Manner', 'Manner', 25, 68]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'नहीं', 'मा', '##ल', '##ू', '##म', 'था', 'यह', '।', '[SEP]'] ['मुझे', 'Experiencer', 'Recipient', 31, 0]\n",
      "['[CLS]', 'मे', '##रे', 'ज', '##हा', '##ज', 'के', 'इ', '##ंजन', 'में', 'एक', 'ब', '##ोल', '##्ट', 'फ', '##ंस', 'गया', 'था', 'तो', 'म', '##ैं', 'उसे', 'न', '##िका', '##लन', '##े', 'में', 'व', '##्य', '##स्त', 'था', '।', '[SEP]'] ['मेरे', 'Possessor', 'Possessor', 32, 0]\n",
      "['[CLS]', 'मे', '##रे', 'ज', '##हा', '##ज', 'के', 'इ', '##ंजन', 'में', 'एक', 'ब', '##ोल', '##्ट', 'फ', '##ंस', 'गया', 'था', 'तो', 'म', '##ैं', 'उसे', 'न', '##िका', '##लन', '##े', 'में', 'व', '##्य', '##स्त', 'था', '।', '[SEP]'] ['के', 'Whole', 'Whole', 32, 8]\n",
      "['[CLS]', 'मे', '##रे', 'ज', '##हा', '##ज', 'के', 'इ', '##ंजन', 'में', 'एक', 'ब', '##ोल', '##्ट', 'फ', '##ंस', 'गया', 'था', 'तो', 'म', '##ैं', 'उसे', 'न', '##िका', '##लन', '##े', 'में', 'व', '##्य', '##स्त', 'था', '।', '[SEP]'] ['में', 'Locus', 'Locus', 32, 14]\n",
      "['[CLS]', 'मे', '##रे', 'ज', '##हा', '##ज', 'के', 'इ', '##ंजन', 'में', 'एक', 'ब', '##ोल', '##्ट', 'फ', '##ंस', 'गया', 'था', 'तो', 'म', '##ैं', 'उसे', 'न', '##िका', '##लन', '##े', 'में', 'व', '##्य', '##स्त', 'था', '।', '[SEP]'] ['उसे', 'Theme', 'Theme', 32, 37]\n",
      "['[CLS]', 'मे', '##रे', 'ज', '##हा', '##ज', 'के', 'इ', '##ंजन', 'में', 'एक', 'ब', '##ोल', '##्ट', 'फ', '##ंस', 'गया', 'था', 'तो', 'म', '##ैं', 'उसे', 'न', '##िका', '##लन', '##े', 'में', 'व', '##्य', '##स्त', 'था', '।', '[SEP]'] ['में', 'Topic', 'Topic', 32, 47]\n",
      "['[CLS]', 'म', '##ैं', 'बड़ी', 'च', '##िं', '##ता', 'में', 'था', 'क्योंकि', 'म', '##र', '##म्', '##मत', 'क', '##ठ', '##िन', 'ल', '##ग', '##ने', 'ल', '##गी', 'थी', '।', '[SEP]'] ['में', 'Characteristic', 'Locus', 33, 12]\n",
      "['[CLS]', 'सबसे', 'ज', '##्यादा', 'ड', '##र', 'पानी', 'स', '##मा', '##प्त', 'होने', 'का', 'था', '।', '[SEP]'] ['सबसे', 'ComparisonRef', 'ComparisonRef', 34, 0]\n",
      "['[CLS]', 'सबसे', 'ज', '##्यादा', 'ड', '##र', 'पानी', 'स', '##मा', '##प्त', 'होने', 'का', 'था', '।', '[SEP]'] ['का', 'Stimulus', 'Gestalt', 34, 26]\n",
      "['[CLS]', 'का', '##ंट', '##े', 'कि', '##स', 'लिए', 'होते', 'हैं', '?', '[SEP]'] ['लिए', 'Purpose', 'Purpose', 35, 8]\n",
      "['[CLS]', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'एक', 'बार', 'प', '##्र', '##श', '##्न', 'करने', 'पर', 'उसे', 'भ', '##ूल', '##ता', 'नहीं', 'था', '।', '[SEP]'] ['पर', 'Time', 'Time', 36, 23]\n",
      "['[CLS]', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'एक', 'बार', 'प', '##्र', '##श', '##्न', 'करने', 'पर', 'उसे', 'भ', '##ूल', '##ता', 'नहीं', 'था', '।', '[SEP]'] ['उसे', 'Topic', 'Theme', 36, 25]\n",
      "['[CLS]', 'म', '##ैं', 'म', '##र', '##म्', '##मत', 'से', 'ख', '##ी', '##जा', 'हुआ', 'था', '।', '[SEP]'] ['से', 'Stimulus', 'Causer', 37, 9]\n",
      "['[CLS]', 'जो', 'भी', 'म', '##ु', '##ं', '##ह', 'में', 'आ', '##ए', 'उत्तर', 'दे', 'देता', 'था', '।', '[SEP]'] ['में', 'Goal', 'Locus', 38, 8]\n",
      "['[CLS]', 'ब', '##स', 'फ', '##ूल', '##ों', 'के', 'प्रति', 'दु', '##ष्ट', '##ता', 'के', 'प', '##्र', '##ती', '##क', 'होते', 'हैं', '।', '[SEP]'] ['के', 'Source', 'Direction', 40, 7]\n",
      "['[CLS]', 'ब', '##स', 'फ', '##ूल', '##ों', 'के', 'प्रति', 'दु', '##ष्ट', '##ता', 'के', 'प', '##्र', '##ती', '##क', 'होते', 'हैं', '।', '[SEP]'] ['के', 'Topic', 'Topic', 40, 21]\n",
      "['[CLS]', 'वह', 'थ', '##ोड़', '##ी', 'दे', '##र', 'तक', 'च', '##ु', '##प', 'रहा', 'फिर', 'झ', '##ु', '##ं', '##झ', '##ला', 'कर', 'उसने', 'प', '##्र', '##श', '##्न', '##ों', 'की', 'एक', 'झ', '##ड़ी', 'लगा', 'दी', '।', '[SEP]'] ['तक', 'Duration', 'EndTime', 42, 10]\n",
      "['[CLS]', 'वह', 'थ', '##ोड़', '##ी', 'दे', '##र', 'तक', 'च', '##ु', '##प', 'रहा', 'फिर', 'झ', '##ु', '##ं', '##झ', '##ला', 'कर', 'उसने', 'प', '##्र', '##श', '##्न', '##ों', 'की', 'एक', 'झ', '##ड़ी', 'लगा', 'दी', '।', '[SEP]'] ['उसने', 'Originator', 'Agent', 42, 29]\n",
      "['[CLS]', 'वह', 'थ', '##ोड़', '##ी', 'दे', '##र', 'तक', 'च', '##ु', '##प', 'रहा', 'फिर', 'झ', '##ु', '##ं', '##झ', '##ला', 'कर', 'उसने', 'प', '##्र', '##श', '##्न', '##ों', 'की', 'एक', 'झ', '##ड़ी', 'लगा', 'दी', '।', '[SEP]'] ['की', 'QuantityItem', 'Stuff', 42, 41]\n",
      "['[CLS]', 'लेकिन', 'म', '##ु', '##झ', '##े', 'ते', '##री', 'बात', 'पर', 'विश्व', '##ास', 'नहीं', 'होता', '।', '[SEP]'] ['मुझे', 'Experiencer', 'Recipient', 43, 5]\n",
      "['[CLS]', 'लेकिन', 'म', '##ु', '##झ', '##े', 'ते', '##री', 'बात', 'पर', 'विश्व', '##ास', 'नहीं', 'होता', '।', '[SEP]'] ['पर', 'Topic', 'Topic', 43, 16]\n",
      "['[CLS]', 'जैसे', 'भी', 'हो', 'अपने', 'को', 'आ', '##श', '##्व', '##स्त', 'कर', 'ले', '##ते', 'हैं', '।', '[SEP]'] ['जैसे', 'Manner', 'ComparisonRef', 45, 0]\n",
      "['[CLS]', 'जैसे', 'भी', 'हो', 'अपने', 'को', 'आ', '##श', '##्व', '##स्त', 'कर', 'ले', '##ते', 'हैं', '।', '[SEP]'] ['को', 'Experiencer', 'Recipient', 45, 12]\n",
      "['[CLS]', 'का', '##ंट', '##ों', 'के', 'होने', 'से', 'वे', 'अपने', 'आ', '##प', 'को', 'स', '##ुर', '##क्षित', 'स', '##म', '##झ', '##ते', 'हो', '##ंग', '##े', '।', '[SEP]'] ['के', 'Theme', 'Theme', 46, 6]\n",
      "['[CLS]', 'का', '##ंट', '##ों', 'के', 'होने', 'से', 'वे', 'अपने', 'आ', '##प', 'को', 'स', '##ुर', '##क्षित', 'स', '##म', '##झ', '##ते', 'हो', '##ंग', '##े', '।', '[SEP]'] ['से', 'Explanation', 'Source', 46, 12]\n",
      "['[CLS]', 'का', '##ंट', '##ों', 'के', 'होने', 'से', 'वे', 'अपने', 'आ', '##प', 'को', 'स', '##ुर', '##क्षित', 'स', '##म', '##झ', '##ते', 'हो', '##ंग', '##े', '।', '[SEP]'] ['को', 'Topic', 'Theme', 46, 22]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'कोई', 'ज', '##वा', '##ब', 'नहीं', 'दिया', '।', '[SEP]'] ['मैंने', 'Originator', 'Agent', 47, 0]\n",
      "['[CLS]', 'म', '##ैं', 'स', '##ो', '##च', 'रहा', 'था', 'अ', '##गर', 'थ', '##ोड़', '##ी', 'दे', '##र', 'में', 'ठ', '##ी', '##क', 'नहीं', 'हुआ', 'तो', 'म', '##ैं', 'ब', '##ोल', '##्ट', 'पर', 'ह', '##थ', '##ौ', '##ड़ा', 'च', '##ला', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['में', 'Time', 'Interval', 48, 22]\n",
      "['[CLS]', 'म', '##ैं', 'स', '##ो', '##च', 'रहा', 'था', 'अ', '##गर', 'थ', '##ोड़', '##ी', 'दे', '##र', 'में', 'ठ', '##ी', '##क', 'नहीं', 'हुआ', 'तो', 'म', '##ैं', 'ब', '##ोल', '##्ट', 'पर', 'ह', '##थ', '##ौ', '##ड़ा', 'च', '##ला', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['पर', 'Goal', 'Locus', 48, 45]\n",
      "['[CLS]', 'उसने', 'फिर', 'मे', '##रा', 'ध्यान', 'ब', '##ंट', '##ा', 'दिया', ',', '[SEP]'] ['उसने', 'Agent', 'Agent', 49, 0]\n",
      "['[CLS]', 'उसने', 'फिर', 'मे', '##रा', 'ध्यान', 'ब', '##ंट', '##ा', 'दिया', ',', '[SEP]'] ['मेरा', 'Experiencer', 'Gestalt', 49, 7]\n",
      "['[CLS]', 'और', 'त', '##ु', '##झ', '##े', 'विश्व', '##ास', 'है', 'कि', 'फ', '##ूल', '.', '.', '.', '[SEP]'] ['तुझे', 'Experiencer', 'Recipient', 50, 2]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'जो', 'भी', 'स', '##म', '##झा', 'ज', '##वा', '##ब', 'दे', 'दिया', '।', '[SEP]'] ['मैंने', 'Recipient', 'Agent', 52, 0]\n",
      "['[CLS]', 'अ', '##क', '##ब', '##क', 'होकर', 'उसने', 'म', '##ु', '##झ', '##े', 'देखा', ',', '[SEP]'] ['उसने', 'Experiencer', 'Agent', 54, 8]\n",
      "['[CLS]', 'अ', '##क', '##ब', '##क', 'होकर', 'उसने', 'म', '##ु', '##झ', '##े', 'देखा', ',', '[SEP]'] ['मुझे', 'Stimulus', 'Theme', 54, 12]\n",
      "['[CLS]', 'उसने', 'देखा', 'कि', 'मे', '##री', 'उ', '##ंग', '##ल', '##िया', '##ं', 'काल', '##ी', 'हो', 'रही', 'हैं', 'और', 'म', '##ैं', 'एक', 'भ', '##ों', '##डी', 'सी', 'च', '##ी', '##ज', 'पर', 'ह', '##थ', '##ौ', '##ड़ा', 'लिए', 'झ', '##ुक', '##ा', 'हुआ', 'था', '।', '[SEP]'] ['उसने', 'Experiencer', 'Agent', 56, 0]\n",
      "['[CLS]', 'उसने', 'देखा', 'कि', 'मे', '##री', 'उ', '##ंग', '##ल', '##िया', '##ं', 'काल', '##ी', 'हो', 'रही', 'हैं', 'और', 'म', '##ैं', 'एक', 'भ', '##ों', '##डी', 'सी', 'च', '##ी', '##ज', 'पर', 'ह', '##थ', '##ौ', '##ड़ा', 'लिए', 'झ', '##ुक', '##ा', 'हुआ', 'था', '।', '[SEP]'] ['मेरी', 'Whole', 'Whole', 56, 10]\n",
      "['[CLS]', 'उसने', 'देखा', 'कि', 'मे', '##री', 'उ', '##ंग', '##ल', '##िया', '##ं', 'काल', '##ी', 'हो', 'रही', 'हैं', 'और', 'म', '##ैं', 'एक', 'भ', '##ों', '##डी', 'सी', 'च', '##ी', '##ज', 'पर', 'ह', '##थ', '##ौ', '##ड़ा', 'लिए', 'झ', '##ुक', '##ा', 'हुआ', 'था', '।', '[SEP]'] ['पर', 'Direction', 'Locus', 56, 51]\n",
      "['[CLS]', 'त', '##ू', 'तो', 'ब', '##ू', '##ढ़', '##ों', 'जैसे', 'बात', '##ें', 'करता', 'है', '।', '[SEP]'] ['जैसे', 'ComparisonRef', 'ComparisonRef', 57, 10]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'थ', '##ोड़', '##ी', 'श', '##र', '##्म', 'आई', 'पर', 'उस', 'पर', 'बिना', 'ध्यान', 'दिए', 'उसने', 'कहा', ',', '[SEP]'] ['मुझे', 'Experiencer', 'Recipient', 58, 0]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'थ', '##ोड़', '##ी', 'श', '##र', '##्म', 'आई', 'पर', 'उस', 'पर', 'बिना', 'ध्यान', 'दिए', 'उसने', 'कहा', ',', '[SEP]'] ['पर', 'Topic', 'Topic', 58, 19]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'थ', '##ोड़', '##ी', 'श', '##र', '##्म', 'आई', 'पर', 'उस', 'पर', 'बिना', 'ध्यान', 'दिए', 'उसने', 'कहा', ',', '[SEP]'] ['बिना', 'Manner', 'Manner', 58, 21]\n",
      "['[CLS]', 'म', '##ु', '##झ', '##े', 'थ', '##ोड़', '##ी', 'श', '##र', '##्म', 'आई', 'पर', 'उस', 'पर', 'बिना', 'ध्यान', 'दिए', 'उसने', 'कहा', ',', '[SEP]'] ['उसने', 'Originator', 'Agent', 58, 33]\n",
      "['[CLS]', 'वा', '##स्त', '##व', 'में', 'वह', 'बहुत', 'च', '##ि', '##ढ़', '##ा', 'हुआ', 'था', '।', '[SEP]'] ['में', 'Circumstance', 'Circumstance', 61, 6]\n",
      "['[CLS]', 'उसके', 'स', '##ुन', '##हर', '##े', 'ब', '##ाल', 'ह', '##वा', 'में', 'उ', '##ड़', 'रहे', 'थे', '।', '[SEP]'] ['उसके', 'Whole', 'Whole', 62, 0]\n",
      "['[CLS]', 'उसके', 'स', '##ुन', '##हर', '##े', 'ब', '##ाल', 'ह', '##वा', 'में', 'उ', '##ड़', 'रहे', 'थे', '।', '[SEP]'] ['में', 'Locus', 'Locus', 62, 16]\n",
      "['[CLS]', 'म', '##ैं', 'एक', 'ऐसे', 'ग', '##्रह', 'के', 'बारे', 'में', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जहां', 'एक', 'ग', '##ु', '##स', '##्स', '##ै', '##ल', 'से', 'ग', '##ु', '##म', '##स', '##ु', '##म', 'रहने', 'वाले', 'म', '##हा', '##श', '##य', 'रहते', 'हैं', '।', '[SEP]'] ['के', 'Topic', 'Topic', 63, 12]\n",
      "['[CLS]', 'म', '##ैं', 'एक', 'ऐसे', 'ग', '##्रह', 'के', 'बारे', 'में', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जहां', 'एक', 'ग', '##ु', '##स', '##्स', '##ै', '##ल', 'से', 'ग', '##ु', '##म', '##स', '##ु', '##म', 'रहने', 'वाले', 'म', '##हा', '##श', '##य', 'रहते', 'हैं', '।', '[SEP]'] ['वाले', 'Characteristic', 'Characteristic', 63, 54]\n",
      "['[CLS]', 'उनका', 'च', '##े', '##हर', '##ा', 'हर', '##द', '##म', 'लाल', 'बना', 'रहता', 'है', '।', '[SEP]'] ['उनका', 'Whole', 'Whole', 64, 0]\n",
      "['[CLS]', 'उन्होंने', 'कभी', 'किसी', 'से', 'प', '##्या', '##र', 'नहीं', 'किया', '।', '[SEP]'] ['उन्होंने', 'Experiencer', 'Agent', 65, 0]\n",
      "['[CLS]', 'उन्होंने', 'कभी', 'किसी', 'से', 'प', '##्या', '##र', 'नहीं', 'किया', '।', '[SEP]'] ['से', 'Stimulus', 'Ancillary', 65, 15]\n",
      "['[CLS]', 'कभी', 'जो', '##ड़', '-', 'घ', '##टा', '##ने', ',', 'ह', '##िस', '##ा', '##ब', '-', 'कि', '##ता', '##ब', 'के', 'अलावा', 'कुछ', 'नहीं', 'किया', '।', '[SEP]'] ['के', 'PartPortion', 'PartPortion', 67, 25]\n",
      "['[CLS]', 'वह', 'भी', 'स', '##ारे', 'दिन', 'ते', '##री', 'तरह', 'क', '##हत', '##ा', 'रहता', 'है', ',', '[SEP]'] ['तेरी', 'ComparisonRef', 'ComparisonRef', 68, 11]\n",
      "['[CLS]', 'म', '##ैं', 'व', '##्य', '##स्त', 'ह', '##ू', '##ं', '-', 'म', '##ु', '##झ', '##े', 'बहुत', 'काम', 'है', '।', '[UNK]', '[SEP]'] ['मुझे', 'Possessor', 'Recipient', 69, 13]\n",
      "['[CLS]', 'और', 'द', '##म्भ', 'से', 'वह', 'फ', '##ूल', '##ा', 'रहता', 'है', '।', '[SEP]'] ['से', 'Theme', 'Instrument', 70, 6]\n",
      "['[CLS]', 'ग', '##ु', '##स', '##्स', '##े', 'से', 'वह', 'न', '##ील', '##ा', '-', 'पी', '##ला', 'होने', 'लगा', '।', '[SEP]'] ['से', 'Causer', 'Causer', 75, 6]\n",
      "['[CLS]', 'य', '##ुग', '-', 'य', '##ुग', 'से', 'फ', '##ूल', '##ों', 'में', 'का', '##ंट', '##े', 'होते', 'च', '##ले', 'आ', '##ए', 'हैं', 'और', 'फिर', 'भ', '##ेड', '##़', 'फ', '##ूल', '##ों', 'को', 'खा', 'जाती', 'रही', 'है', '।', '[SEP]'] ['से', 'Duration', 'StartTime', 76, 7]\n",
      "['[CLS]', 'य', '##ुग', '-', 'य', '##ुग', 'से', 'फ', '##ूल', '##ों', 'में', 'का', '##ंट', '##े', 'होते', 'च', '##ले', 'आ', '##ए', 'हैं', 'और', 'फिर', 'भ', '##ेड', '##़', 'फ', '##ूल', '##ों', 'को', 'खा', 'जाती', 'रही', 'है', '।', '[SEP]'] ['में', 'Locus', 'Locus', 76, 14]\n",
      "['[CLS]', 'य', '##ुग', '-', 'य', '##ुग', 'से', 'फ', '##ूल', '##ों', 'में', 'का', '##ंट', '##े', 'होते', 'च', '##ले', 'आ', '##ए', 'हैं', 'और', 'फिर', 'भ', '##ेड', '##़', 'फ', '##ूल', '##ों', 'को', 'खा', 'जाती', 'रही', 'है', '।', '[SEP]'] ['को', 'Theme', 'Theme', 76, 48]\n",
      "['[CLS]', 'यह', 'स', '##म', '##झ', '##ने', 'की', 'को', '##श', '##िश', 'करना', 'महत्वपूर्ण', 'नहीं', 'है', 'क्योंकि', 'आ', '##ख', '##िर', 'फ', '##ूल', 'एक', 'ऐसी', 'च', '##ी', '##ज', 'को', 'क', '##्यो', '##ं', 'वह', '##न', 'करते', 'हैं', 'जिसका', 'कोई', 'इस्तेमाल', 'न', 'हो', '?', '[SEP]'] ['की', 'Theme', 'Theme', 77, 7]\n",
      "['[CLS]', 'यह', 'स', '##म', '##झ', '##ने', 'की', 'को', '##श', '##िश', 'करना', 'महत्वपूर्ण', 'नहीं', 'है', 'क्योंकि', 'आ', '##ख', '##िर', 'फ', '##ूल', 'एक', 'ऐसी', 'च', '##ी', '##ज', 'को', 'क', '##्यो', '##ं', 'वह', '##न', 'करते', 'हैं', 'जिसका', 'कोई', 'इस्तेमाल', 'न', 'हो', '?', '[SEP]'] ['को', 'Theme', 'Theme', 77, 56]\n",
      "['[CLS]', 'यह', 'स', '##म', '##झ', '##ने', 'की', 'को', '##श', '##िश', 'करना', 'महत्वपूर्ण', 'नहीं', 'है', 'क्योंकि', 'आ', '##ख', '##िर', 'फ', '##ूल', 'एक', 'ऐसी', 'च', '##ी', '##ज', 'को', 'क', '##्यो', '##ं', 'वह', '##न', 'करते', 'हैं', 'जिसका', 'कोई', 'इस्तेमाल', 'न', 'हो', '?', '[SEP]'] ['जिसका', 'Gestalt', 'Gestalt', 77, 73]\n",
      "['[CLS]', 'फ', '##ूल', 'और', 'भ', '##ेड', '##़', 'की', 'च', '##ली', 'आ', 'रही', 'ल', '##ड़ा', '##ई', 'महत्वपूर्ण', 'नहीं', 'है', 'क', '##्या', '?', '[SEP]'] ['की', 'Agent', 'Whole', 78, 9]\n",
      "['[CLS]', 'क', '##्या', 'इसे', 'स', '##म', '##झ', '##ना', 'एक', 'ग', '##ोल', '-', 'म', '##ट', '##ोल', 'म', '##हा', '##श', '##य', 'के', 'जो', '##ड़', '-', 'घ', '##टा', '##ने', 'से', 'ज', '##्यादा', 'ग', '##ंभ', '##ीर', 'बात', 'नहीं', '?', '[SEP]'] ['इसे', 'Topic', 'Theme', 79, 4]\n",
      "['[CLS]', 'क', '##्या', 'इसे', 'स', '##म', '##झ', '##ना', 'एक', 'ग', '##ोल', '-', 'म', '##ट', '##ोल', 'म', '##हा', '##श', '##य', 'के', 'जो', '##ड़', '-', 'घ', '##टा', '##ने', 'से', 'ज', '##्यादा', 'ग', '##ंभ', '##ीर', 'बात', 'नहीं', '?', '[SEP]'] ['के', 'Agent', 'Gestalt', 79, 27]\n",
      "['[CLS]', 'क', '##्या', 'इसे', 'स', '##म', '##झ', '##ना', 'एक', 'ग', '##ोल', '-', 'म', '##ट', '##ोल', 'म', '##हा', '##श', '##य', 'के', 'जो', '##ड़', '-', 'घ', '##टा', '##ने', 'से', 'ज', '##्यादा', 'ग', '##ंभ', '##ीर', 'बात', 'नहीं', '?', '[SEP]'] ['से', 'ComparisonRef', 'ComparisonRef', 79, 39]\n",
      "['[CLS]', 'और', 'यदि', 'म', '##ैं', 'क', '##ह', '##ू', '##ं', 'कि', 'म', '##ैं', 'एक', 'ऐसे', 'फ', '##ूल', 'को', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जो', 'स', '##िर', '##्फ', 'मे', '##री', 'दुनिया', 'में', 'होता', 'है', 'और', 'उसे', 'एक', 'भ', '##ेड', '##़', 'एक', 'दिन', 'ऐसे', 'ही', 'बिना', 'स', '##ो', '##चे', '-', 'स', '##म', '##झ', '##े', 'च', '##र', 'सकती', 'है', 'तो', 'यह', 'महत्वपूर्ण', 'बात', 'नहीं', '?', '[SEP]'] ['को', 'Topic', 'Theme', 80, 25]\n",
      "['[CLS]', 'और', 'यदि', 'म', '##ैं', 'क', '##ह', '##ू', '##ं', 'कि', 'म', '##ैं', 'एक', 'ऐसे', 'फ', '##ूल', 'को', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जो', 'स', '##िर', '##्फ', 'मे', '##री', 'दुनिया', 'में', 'होता', 'है', 'और', 'उसे', 'एक', 'भ', '##ेड', '##़', 'एक', 'दिन', 'ऐसे', 'ही', 'बिना', 'स', '##ो', '##चे', '-', 'स', '##म', '##झ', '##े', 'च', '##र', 'सकती', 'है', 'तो', 'यह', 'महत्वपूर्ण', 'बात', 'नहीं', '?', '[SEP]'] ['मेरी', 'Gestalt', 'Gestalt', 80, 42]\n",
      "['[CLS]', 'और', 'यदि', 'म', '##ैं', 'क', '##ह', '##ू', '##ं', 'कि', 'म', '##ैं', 'एक', 'ऐसे', 'फ', '##ूल', 'को', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जो', 'स', '##िर', '##्फ', 'मे', '##री', 'दुनिया', 'में', 'होता', 'है', 'और', 'उसे', 'एक', 'भ', '##ेड', '##़', 'एक', 'दिन', 'ऐसे', 'ही', 'बिना', 'स', '##ो', '##चे', '-', 'स', '##म', '##झ', '##े', 'च', '##र', 'सकती', 'है', 'तो', 'यह', 'महत्वपूर्ण', 'बात', 'नहीं', '?', '[SEP]'] ['में', 'Locus', 'Locus', 80, 52]\n",
      "['[CLS]', 'और', 'यदि', 'म', '##ैं', 'क', '##ह', '##ू', '##ं', 'कि', 'म', '##ैं', 'एक', 'ऐसे', 'फ', '##ूल', 'को', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जो', 'स', '##िर', '##्फ', 'मे', '##री', 'दुनिया', 'में', 'होता', 'है', 'और', 'उसे', 'एक', 'भ', '##ेड', '##़', 'एक', 'दिन', 'ऐसे', 'ही', 'बिना', 'स', '##ो', '##चे', '-', 'स', '##म', '##झ', '##े', 'च', '##र', 'सकती', 'है', 'तो', 'यह', 'महत्वपूर्ण', 'बात', 'नहीं', '?', '[SEP]'] ['उसे', 'Theme', 'Theme', 80, 63]\n",
      "['[CLS]', 'और', 'यदि', 'म', '##ैं', 'क', '##ह', '##ू', '##ं', 'कि', 'म', '##ैं', 'एक', 'ऐसे', 'फ', '##ूल', 'को', 'जा', '##न', '##ता', 'ह', '##ू', '##ं', 'जो', 'स', '##िर', '##्फ', 'मे', '##री', 'दुनिया', 'में', 'होता', 'है', 'और', 'उसे', 'एक', 'भ', '##ेड', '##़', 'एक', 'दिन', 'ऐसे', 'ही', 'बिना', 'स', '##ो', '##चे', '-', 'स', '##म', '##झ', '##े', 'च', '##र', 'सकती', 'है', 'तो', 'यह', 'महत्वपूर्ण', 'बात', 'नहीं', '?', '[SEP]'] ['बिना', 'Manner', 'Manner', 80, 82]\n",
      "['[CLS]', 'वह', 'श', '##र', '##्म', 'से', 'लाल', 'हो', 'रहा', 'था', '।', '[SEP]'] ['से', 'Causer', 'Causer', 81, 6]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'ऐसे', 'फ', '##ूल', 'को', 'प', '##्या', '##र', 'कर', '##े', 'जो', 'को', '##ट', '##ि', '-', 'को', '##ट', '##ि', 'त', '##ार', '##ों', 'में', 'क', '##ही', '##ं', 'न', 'पाया', 'जाता', 'हो', '-', 'एक', '##द', '##म', 'ब', '##ेम', '##िस', '##ाल', 'हो', ',', 'तो', 'वह', 'आ', '##समा', '##न', 'में', 'फ', '##ै', '##ले', 'स', '##िता', '##रों', 'को', 'न', '##ि', '##हार', '##ने', 'मात्रा', 'से', 'प', '##्र', '##सन', '##्न', 'हो', 'जा', '##ए', '##गा', '।', '[SEP]'] ['को', 'Stimulus', 'Theme', 83, 12]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'ऐसे', 'फ', '##ूल', 'को', 'प', '##्या', '##र', 'कर', '##े', 'जो', 'को', '##ट', '##ि', '-', 'को', '##ट', '##ि', 'त', '##ार', '##ों', 'में', 'क', '##ही', '##ं', 'न', 'पाया', 'जाता', 'हो', '-', 'एक', '##द', '##म', 'ब', '##ेम', '##िस', '##ाल', 'हो', ',', 'तो', 'वह', 'आ', '##समा', '##न', 'में', 'फ', '##ै', '##ले', 'स', '##िता', '##रों', 'को', 'न', '##ि', '##हार', '##ने', 'मात्रा', 'से', 'प', '##्र', '##सन', '##्न', 'हो', 'जा', '##ए', '##गा', '।', '[SEP]'] ['में', 'Locus', 'Locus', 83, 38]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'ऐसे', 'फ', '##ूल', 'को', 'प', '##्या', '##र', 'कर', '##े', 'जो', 'को', '##ट', '##ि', '-', 'को', '##ट', '##ि', 'त', '##ार', '##ों', 'में', 'क', '##ही', '##ं', 'न', 'पाया', 'जाता', 'हो', '-', 'एक', '##द', '##म', 'ब', '##ेम', '##िस', '##ाल', 'हो', ',', 'तो', 'वह', 'आ', '##समा', '##न', 'में', 'फ', '##ै', '##ले', 'स', '##िता', '##रों', 'को', 'न', '##ि', '##हार', '##ने', 'मात्रा', 'से', 'प', '##्र', '##सन', '##्न', 'हो', 'जा', '##ए', '##गा', '।', '[SEP]'] ['में', 'Locus', 'Locus', 83, 80]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'ऐसे', 'फ', '##ूल', 'को', 'प', '##्या', '##र', 'कर', '##े', 'जो', 'को', '##ट', '##ि', '-', 'को', '##ट', '##ि', 'त', '##ार', '##ों', 'में', 'क', '##ही', '##ं', 'न', 'पाया', 'जाता', 'हो', '-', 'एक', '##द', '##म', 'ब', '##ेम', '##िस', '##ाल', 'हो', ',', 'तो', 'वह', 'आ', '##समा', '##न', 'में', 'फ', '##ै', '##ले', 'स', '##िता', '##रों', 'को', 'न', '##ि', '##हार', '##ने', 'मात्रा', 'से', 'प', '##्र', '##सन', '##्न', 'हो', 'जा', '##ए', '##गा', '।', '[SEP]'] ['को', 'Stimulus', 'Theme', 83, 94]\n",
      "['[CLS]', 'अ', '##गर', 'कोई', 'ऐसे', 'फ', '##ूल', 'को', 'प', '##्या', '##र', 'कर', '##े', 'जो', 'को', '##ट', '##ि', '-', 'को', '##ट', '##ि', 'त', '##ार', '##ों', 'में', 'क', '##ही', '##ं', 'न', 'पाया', 'जाता', 'हो', '-', 'एक', '##द', '##म', 'ब', '##ेम', '##िस', '##ाल', 'हो', ',', 'तो', 'वह', 'आ', '##समा', '##न', 'में', 'फ', '##ै', '##ले', 'स', '##िता', '##रों', 'को', 'न', '##ि', '##हार', '##ने', 'मात्रा', 'से', 'प', '##्र', '##सन', '##्न', 'हो', 'जा', '##ए', '##गा', '।', '[SEP]'] ['से', 'Stimulus', 'Causer', 83, 109]\n",
      "['[CLS]', 'लेकिन', 'यदि', 'उसे', 'भ', '##ेड', '##़', 'च', '##र', 'जा', '##ए', 'तो', 'स', '##ारे', 'त', '##ारे', 'उसके', 'लिए', 'ब', '##ु', '##झ', 'से', 'जा', '##एं', '##गे', '।', '[SEP]'] ['उसे', 'Theme', 'Theme', 84, 8]\n",
      "['[CLS]', 'लेकिन', 'यदि', 'उसे', 'भ', '##ेड', '##़', 'च', '##र', 'जा', '##ए', 'तो', 'स', '##ारे', 'त', '##ारे', 'उसके', 'लिए', 'ब', '##ु', '##झ', 'से', 'जा', '##एं', '##गे', '।', '[SEP]'] ['उसके', 'Beneficiary', 'Beneficiary', 84, 30]\n",
      "['[CLS]', 'इसके', 'बाद', 'वह', 'कुछ', 'नहीं', 'क', '##ह', 'स', '##का', '।', '[SEP]'] ['इसके', 'Time', 'Time', 86, 0]\n",
      "['[CLS]', 'जो', '##र', 'की', 'स', '##ु', '##ब', '##कि', '##या', '##ं', 'ले', '##ने', 'लगा', '।', '[SEP]'] ['की', 'Characteristic', 'Identity', 87, 3]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'अपने', 'औ', '##जार', 'र', '##ख', 'दिए', '।', '[SEP]'] ['मैंने', 'Agent', 'Agent', 89, 0]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'अपने', 'औ', '##जार', 'र', '##ख', 'दिए', '।', '[SEP]'] ['अपने', 'Possessor', 'Possessor', 89, 5]\n",
      "['[CLS]', 'ब', '##ोल', '##्ट', ',', 'ह', '##थ', '##ौ', '##ड़ा', ',', 'प', '##्यास', ',', 'म', '##ौ', '##त', '-', 'इन', '##का', 'कोई', 'अर्थ', 'नहीं', 'र', '##ह', 'गया', 'था', '।', '[SEP]'] ['इनका', 'Gestalt', 'Gestalt', 90, 23]\n",
      "['[CLS]', 'एक', 'ग', '##्रह', 'पर', ',', 'मे', '##री', 'ध', '##रत', '##ी', 'पर', ',', 'एक', 'न', '##न्', '##हा', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'था', '.', '.', '.', '[SEP]'] ['पर', 'Locus', 'Locus', 91, 6]\n",
      "['[CLS]', 'एक', 'ग', '##्रह', 'पर', ',', 'मे', '##री', 'ध', '##रत', '##ी', 'पर', ',', 'एक', 'न', '##न्', '##हा', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'था', '.', '.', '.', '[SEP]'] ['मेरी', 'Gestalt', 'Gestalt', 91, 9]\n",
      "['[CLS]', 'एक', 'ग', '##्रह', 'पर', ',', 'मे', '##री', 'ध', '##रत', '##ी', 'पर', ',', 'एक', 'न', '##न्', '##हा', 'र', '##ाज', '##क', '##ु', '##मा', '##र', 'था', '.', '.', '.', '[SEP]'] ['पर', 'Locus', 'Locus', 91, 17]\n",
      "['[CLS]', 'उसे', 'स', '##ांत', '##्व', '##ना', 'दे', '##नी', 'थी', '।', '[SEP]'] ['उसे', 'Recipient', 'Recipient', 92, 0]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'उसे', 'ब', '##ा', '##ं', '##ह', '##ो', 'में', 'भर', 'लिया', 'था', '।', '[SEP]'] ['मैंने', 'Agent', 'Agent', 93, 0]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'उसे', 'ब', '##ा', '##ं', '##ह', '##ो', 'में', 'भर', 'लिया', 'था', '।', '[SEP]'] ['उसे', 'Theme', 'Theme', 93, 5]\n",
      "['[CLS]', 'म', '##ैं', '##ने', 'उसे', 'ब', '##ा', '##ं', '##ह', '##ो', 'में', 'भर', 'लिया', 'था', '।', '[SEP]'] ['में', 'Goal', 'Locus', 93, 13]\n",
      "['[CLS]', 'उसे', 'थ', '##प', '##थ', '##पा', '##या', ',', 'झ', '##ुल', '##ाया', 'और', 'ब', '##ोल', '##ा', ',', '[SEP]'] ['उसे', 'Theme', 'Theme', 94, 0]\n",
      "['[CLS]', 'जिस', 'फ', '##ूल', 'को', 'त', '##ू', 'प', '##्या', '##र', 'करता', 'है', 'उसे', 'कोई', 'भ', '##य', 'नहीं', '.', '.', '.', '[SEP]'] ['को', 'Stimulus', 'Theme', 95, 6]\n",
      "['[CLS]', 'जिस', 'फ', '##ूल', 'को', 'त', '##ू', 'प', '##्या', '##र', 'करता', 'है', 'उसे', 'कोई', 'भ', '##य', 'नहीं', '.', '.', '.', '[SEP]'] ['उसे', 'Experiencer', 'Recipient', 95, 21]\n",
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['तेरी', 'Possessor', 'Possessor', 96, 3]\n",
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['का', 'Whole', 'Whole', 96, 11]\n",
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['के', 'Purpose', 'Purpose', 96, 24]\n",
      "['[CLS]', 'म', '##ैं', 'ते', '##री', 'भ', '##ेड', '##़', 'का', 'म', '##ु', '##ं', '##ह', 'ब', '##ंद', 'करने', 'के', 'लिए', 'एक', 'जा', '##बा', 'बना', 'द', '##ू', '##ंगा', ',', 'ते', '##रे', 'फ', '##ूल', 'के', 'लिए', 'क', '##व', '##च', 'बना', 'द', '##ू', '##ंगा', '।', '[SEP]'] ['तेरे', 'Possessor', 'Possessor', 96, 44]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "44",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1897c7c771d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcatenated_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 44"
     ]
    }
   ],
   "source": [
    "print(len(data), len(concatenated_embeddings))\n",
    "print(data[0])\n",
    "for i in data:\n",
    "    print(sentences[i[3]], i)\n",
    "    if len(concatenated_embeddings[i[3]][i[4]]) != 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from '/Users/aryamanarora/Documents/computerscience/CARMLS/prediction/models.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = models.SNACSDataset(data, concatenated_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.40436467e+01 -7.76951992e+00 -6.68051757e+00 ...  1.23863055e-18\n",
      " -3.55762774e-19  2.17371899e-19]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA()\n",
    "components = pca.fit_transform(real_data.df.loc[:,:'e3071'])\n",
    "print(components[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e0             0.328664\n",
      "e1            -0.181971\n",
      "e2              1.37394\n",
      "e3             0.298746\n",
      "e4             0.021552\n",
      "               ...     \n",
      "e3070          0.814385\n",
      "e3071        -0.0695136\n",
      "scene       Experiencer\n",
      "function          Agent\n",
      "name              मैंने\n",
      "Name: 0, Length: 3075, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(real_data.df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(components[:,0], components[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-385bc2409294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'मुझे'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'को'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'तुझको'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'उसको'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'तुमको'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "for i in ['मुझे', 'को', 'तुझको', 'उसको', 'तुमको']:\n",
    "    plt.scatter(components[real_data.df['name']==i][:,0], components[real_data.df['name']==i][:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
